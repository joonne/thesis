\documentclass[main.tex]{thesis.tex}
\begin{document}

\chapter{Toteutus}

GroupLens Research on ker‰nnyt ja laittanut saataville arvioaineistoja MovieLens sivustolta.
Aineistot on ker‰tty useiden aikajaksojen aikana, riippuen aineston koosta.
MovieLens ml-latest-small aineisto sis‰lt‰‰ 100 000 arviota, jotka ovat antaneet 700 k‰ytt‰j‰‰ 9000 elokuvalle.
N‰iden aineistojen haittapuolena on, ett‰ ne muuttuvat ajan myˆt‰, eiv‰tk‰ n‰in ollen ole sopivia tutkimustulosten raportointiin.
Nykyinen, lokakuussa 2016 julkistettu versio on saatavilla projektin versionhallinnassa.
T‰m‰ aineisto valittiin, jottai voitaisiin antaa arvioita elokuville, jotka on oikeasti n‰hty ja myˆs laitteiston vuoksi.
MovieLens ml-latest-small aineisto koostuu $movies.csv$ and $ratings.csv$ tiedostoista.

\captionof{table}{movies.csv}
\begin{tabular}{lll}
	movieId & title & genres \\ \hline
	1 & Toy Story (1995) & Adventure|Animation|Children \\
	2 & Jumanji (1995) & Adventure|Children|Fantasy \\
	3 & Grumpier Old Men (1995) & Comedy|Romance \\
	4 & Waiting to Exhale (1995) & Comedy|Drama|Romance \\
	5 & Father of the Bride Part II (1995) & Comedy \\
	6 & Heat (1995) & Action|Crime|Thriller \\
	7 & Sabrina (1995) & Comedy|Romance \\
	8 & Tom and Huck (1995) & Adventure|Children \\
	9 & Sudden Death (1995) & Action \\
	10 & GoldenEye (1995) & Action|Adventure|Thriller \\
\end{tabular}

\captionof{table}{ratings.csv}
\begin{tabular}{llll}
	userId & movieId & rating & timestamp \\ \hline
	1 & 31 & 2.5 & 1260759144 \\
	1 & 1029 & 3.0 & 1260759179 \\
	1 & 1061 & 3.0 & 1260759182 \\
	1 & 1129 & 2.0 & 1260759185 \\
	1 & 1172 & 4.0 & 1260759205 \\
	1 & 1263 & 2.0 & 1260759151 \\
	1 & 1287 & 2.0 & 1260759187 \\
	1 & 1293 & 2.0 & 1260759148 \\
	1 & 1339 & 3.5 & 1260759125 \\
\end{tabular}

Toteutuksessa k‰ytettiin RDD-pohjaista rajapintaa, sill‰ dataset-pohjainen rajapinta ei ole viel‰ t‰ysin toiminnallinen yhteisˆllisen suodatuksen teht‰viss‰.
Aineiston lataaminen voidaan tehd‰ dataset rajapintaa hyˆdynt‰en, mutta varsinaisen suositus t‰ytyy tehd‰ RDD rajapintaa k‰ytt‰en.
Dataset rajapinta tarjoaa useita parannuksia, kuten esimerkiksi yksinkertaisemman tiedon lataamisen.

\section{MovieLensRecommendation.scala}

Ensimm‰inen askel itsen‰isen spark sovelluksen rakentamisessa on tehd‰ oikeanlainen kansiorakenne ja tehd‰ $<PROJEKTI>.sbt$ niminen tiedosto, jossa kuvaillaan sovelluksen riippuvuudet.
Itsen‰inen spark sovellus tarkoittaa k‰yttˆvalmista $jar$ tiedostoa (Java ARchive) joka voidaan jakaa spark klusterille ja se sis‰lt‰‰ sek‰ koodin ett‰ kaikki riippuvuudet.

Sovelluksia voidaan ottaa k‰yttˆˆn klusterissa spark-submit tyˆkalun avulla.
Spark-submit mahdollistaa Sparkin kaikkien tuettujen klusterinhoitajien k‰ytt‰misen yhtein‰isen k‰yttˆliittym‰n kautta, joten k‰ytt‰j‰n ei tarvitse m‰‰ritt‰‰ sovellusta toimimaan erikseen kaikkien kanssa.

\begin{lstlisting}[caption=Kokoonpano jar-tiedoston tekeminen sbt tyˆkalulla,language=sh]
sbt package
\end{lstlisting}

\begin{lstlisting}[caption=Sovelluksen k‰yttˆˆnotto klusterissa,language=sh]
spark-submit --class "MovieLensALS" --master local[4] movielens-recommendations_2.11-1.0.jar
\end{lstlisting}

\lstset {
	language=Scala,
	basicstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	showstringspaces=false,
	tabsize=2,
	breaklines=true,
	breakatwhitespace=false,
}

\begin{lstlisting}[caption=Suositusten lataaminen RDD rajapintaa k‰ytt‰en]
val ratings = sc.textFile("ml-latest-small/ratings.csv")
  .filter(x => !isHeader("userId", x))
  .map { line =>
    val fields = line.split(",")
    val timestamp = fields(3).toLong % 10
    val userId = fields(0).toInt
    val movieId = fields(1).toInt
    val rating = fields(2).toDouble 

    (timestamp, Rating(userId, movieId, rating))
  }
\end{lstlisting}

\lstset {
	language=Scala,
	basicstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	showstringspaces=false,
	tabsize=2,
	breaklines=true,
	breakatwhitespace=false,
}

\begin{lstlisting}[caption=Suositusten lataaminen dataset rajapintaa k‰ytt‰en]
val ratings = spark.read.csv("ml-latest-small/ratings.csv")
	.filter(arr => arr(0) != "userId")
	.map { fields =>
		val userId = fields(0).asInstanceOf[String].toInt
		val movieId = fields(1).asInstanceOf[String].toInt
		val rating = fields(2).asInstanceOf[String].toFloat
		val timestamp = fields(3).asInstanceOf[String].toDouble % 10

		Rating(userId, movieId, rating, timestamp)
  }
\end{lstlisting}

\lstset {
	language=Scala,
	basicstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	showstringspaces=false,
	tabsize=2,
	breaklines=true,
	breakatwhitespace=false,
}

\begin{lstlisting}[caption=MovieLensALS.scala]
import org.apache.spark.mllib.recommendation._

object MovieLensALS {
	def main(args: Array[String]) {

		val conf = new SparkConf()
			.setAppName("MovieLensALS")
			.set("spark.executor.memory", "4g")
		val sc = new SparkContext(conf)
	
		/* load personal ratings */
		val personalRatings = Source.fromFile("personalRatings.txt")
			.getLines()
			.map { line =>
					val fields = line.split(",")
					Rating(fields(0).toInt, fields(1).toInt, fields(2).toDouble)
			}.toSeq
		
		val personalRatingsRDD = sc.parallelize(personalRatings, 1)
		
		/* load ratings and movie titles */
		val ratings = sc.textFile("ml-latest-small/ratings.csv")
			.filter(x => !isHeader("userId", x))
			.map { line =>
					val fields = line.split(",")
					val timestamp = fields(3).toLong % 10
					val userId = fields(0).toInt
					val movieId = fields(1).toInt
					val rating = fields(2).toDouble)

					(timestamp, Rating(userId, movieId, rating)
			}
		
		val movies = sc.textFile("ml-latest-small/movies.csv")
			.filter(x => !isHeader("movieId", x))
			.map { line =>
					val fields = line.split(",")
					(fields(0).toInt, fields(1))
			}.collect().toMap
		
		val numRatings = ratings.count
		val numUsers = ratings.map(_._2.user).distinct.count
		val numMovies = ratings.map(_._2.product).distinct.count
		
		val numPartitions = 4
		val training = ratings.filter(x => x._1 < 6)
			.values
			.union(personalRatingsRDD)
			.repartition(numPartitions)
			.cache()
		val validation = ratings.filter(x => x._1 >= 6 && x._1 < 8)
			.values
			.repartition(numPartitions)
			.cache()
		val test = ratings.filter(x => x._1 >= 8).values.cache()
		
		val numTraining = training.count()
		val numValidation = validation.count()
		val numTest = test.count()
		
		/* training */
		
		val ranks = List(8, 12)
		val lambdas = List(1.0, 10.0)
		val numIters = List(10, 20)
		var bestModel: Option[MatrixFactorizationModel] = None
		var bestValidationRmse = Double.MaxValue
		var bestRank = 0
		var bestLambda = -1.0
		var bestNumIter = -1
		for (rank <- ranks; lambda <- lambdas; numIter <- numIters) {
			val model = ALS.train(training, rank, numIter, lambda)
			val validationRmse =
					computeRmse(model, validation, numValidation)
			
			if (validationRmse < bestValidationRmse) {
					bestModel = Some(model)
					bestValidationRmse = validationRmse
					bestRank = rank
					bestLambda = lambda
					bestNumIter = numIter
			}
		}
		
		val testRmse = computeRmse(bestModel.get, test, numTest)
		
		val myRatedMovieIds = personalRatings.map(_.product).toSet
		val candidates = sc.parallelize(
				movies.keys.filter(!myRatedMovieIds.contains(_)).toSeq
		)
		val recommendations = bestModel.get
			.predict(candidates.map((0, _)))
			.collect()
			.sortBy(- _.rating)
			.take(10)
		
		var i = 1
		println("Movies recommended for you:")
		recommendations.foreach { r =>
			println("%2d".format(i) + ": " + movies(r.product))
			i += 1
		}
		
		// clean up
		sc.stop()
	}
	
	def isHeader(id: String, line: String): Boolean = line.contains(id)
	
	/** Compute RMSE */
	def computeRmse(
			model: MatrixFactorizationModel,
			data: RDD[Rating],
			n: Long
	): Double = {
		val predictions: RDD[Rating] =
			model.predict(data.map(x => (x.user, x.product)))
		val predictionsAndRatings =
			predictions.map(x => ((x.user, x.product), x.rating))
				.join(data.map(x => ((x.user, x.product), x.rating)))
				.values
		
		math.sqrt(
			predictionsAndRatings
				.map(x => (x._1 - x._2) * (x._1 - x._2))
				.reduce(_ + _) / n
		)
	}
}
\end{lstlisting}

Rivill‰ 1 tuodaan saataville kaikki recommendation paketin sis‰lt‰m‰t kent‰t tai metodit k‰ytt‰en $import$ avainsanaa.
Rivill‰ 3 m‰‰ritell‰‰n MovieLensALS niminen objekti.
Objekti on nimetty instanssi joka sis‰lt‰‰ j‰seni‰ kuten kentti‰ (field) sek‰ metodeita (method).
Rivill‰ 4 on m‰‰ritelty $main$ funktio tarkoittaa sit‰, ett‰ m‰‰ritelty objekti $MovieLensALS$ on ohjelman aloituspiste (entry point) sill‰ $main$ funktio sis‰lt‰‰ tietynlaisen allekirjoituksen eli tietynlaiset parametrit.
Riveill‰ 6-9 luodaan $SparkConf$ objekti, jonka avulla luodaan ohjelman k‰yttˆˆn uusi $SparkContext$ objekti. $SparkContext$ objektin avulla p‰‰st‰‰n k‰siksi Sparkin sis‰isiin toiminnallisuuksiin.
Riveill‰ 11-17 ladataan henkilˆkohtaiset suositukset tekstitiedostosta nimelt‰ $personalRatings.txt$, pilkotaan tiedoston rivit pilkun kohdalta ja luodaan uusia $Rating$ objekteja yht‰ monta, kuin tiedostossa on rivej‰.
Rivill‰ 19 ladatut suositukset muutetaan viel‰ RDD (Resilient Distributed Dataset) muotoiseksi k‰ytt‰en $sc.parallelize$ funktiota.
Funktiolle annettava toinen parametri tarkoittaa hajautuksen m‰‰r‰‰, eli kuinka monelle solmulle klusterissa tiedosto halutaan hajauttaa.
Riveill‰ 22-36 luodaan RDD oliot $ratings$ ja $movies$ lataamalla kaksi erillist‰ csv tiedostoa.
Tiedostoista suodatetaan ensin pois otsikkorivit k‰ytt‰en $isHeader$ apufunktiota.
T‰m‰n j‰lkeen tiedosto k‰yd‰‰n l‰pi rivi kerrallaan ja p‰tkit‰‰n pilkulla erotetut arvot taulukkoon k‰ytt‰en Scalan String luokan sis‰‰nrakennettua $split$ funktiota.
T‰m‰n j‰lkeen taulukossa olevista arvoista muodostetaan Tupleja.
Riveill‰ 44-54 valmistellaan opetus, validaatio sek‰ testidatat.
Rivill‰ 47 opetusdataan lis‰t‰‰n omat henkilˆkohtaiset arvostelut k‰ytt‰en RDD:n union funktiota.

Riveill‰ 64-83 suoritetaan varsinainen mallin opetus.

Opetus suoritetaan niin, ett‰ opetetaan muutama versio mallista, ja lopuksi valitaan opetetuista malleista paras k‰ytt‰en RMSE-metriikkaa mittarina.

Varsinainen mallin opetus tehd‰‰n k‰ytt‰en ALS kirjaston funktiota $train$ ja tarkemmin sanottuna $train$ funktion ylikuormitettua versiota, joka ottaa sis‰‰ntulonaan $ratings$, $rank$, $iterations$ sek‰ $lambda$ parametrit.
Ratings on RDD Rating olioita, jotka sis‰lt‰v‰t k‰ytt‰j‰n id:n, elokuvan id:n ja suosituksen.
Rank tarkoittaa piilevien ominaisuuksien sis‰llytett‰v‰‰ m‰‰r‰‰.
Iterations tarkoittaa ALS algoritmien iteraatioiden m‰‰r‰‰.
Lambda tarkoittaa regularisaatio parametria, jolla yritet‰‰n ehk‰ist‰ mallin ylioppimista.

Riveill‰ 89-102 haetaan henkilˆkohtaiset suositukset k‰ytt‰m‰ll‰ mallin $predict$ metodia, joka ottaa parametrinaan mahdollisten elokuvien joukon.
Mahdollisilla elokuvilla tarkoitetaan elokuvia joita k‰ytt‰j‰ ei ole viel‰ n‰hnyt, eli ne eiv‰t sis‰lly $personalRatings$ muuttujan sis‰lt‰miin elokuviin.
Rivill‰ 105 kutsutaan lopuksi $sparkContext$ objektin $stop$ funktiota, jolla kerrotaan ett‰ laskenta on suoritettu loppuun.


\section{Apache Pig}

Koska valmiita personoituja suositteluj‰rjestelmi‰ ei vaikuttanut olevan saatavilla, tuloksia vertaillaan ei-personoituihin, Apache Pig j‰rjestelm‰ll‰ saatuihin tuloksiin.
Apache Pig on suurten datasettien analysointiin tarkoitettu alusta, joka sis‰lt‰‰ korkean tason kielen data-analyysi sovellusten ilmaisemiseen sek‰ infrastruktuurin n‰iden ohjelmien k‰ytt‰miseen.
Pig ohjelmien rakenne mahdollistaa merkitt‰v‰n rinnakkaistamisen, joka puolestaan mahdollistaa todella suurten datasettien k‰sittelyn. \cite{pig17}

T‰ll‰ hetkell‰ Pig:n infrastruktuurikerros koostuu k‰‰nt‰j‰st‰ joka tuottaa Map-Reduce ohjelmien p‰tki‰, joille suurimittaiset rinnakkaiset toteutukset lˆytyv‰t valmiina.
Pig:n kielikerros koostuu kielest‰ nimelt‰ Pig Latin, jolla on seuraavat ominaisuudet:

Ohjelmoinnin helppous.
Rinnakkaisesti suoritettavien data-analyysi ohjelmien kirjoittaminen on helppoa.
Monimutkaiset, useista toisistaan riippuvista datamuunnokset enkoodataan eksplisiittisesti data virtaus (flow) sekvenssein‰, jolloin niiden kirjoittaminen, ymm‰rt‰minen ja hallinta helpottuu.
Optimointimahdollisuudet.
Suorituksen automaattinen optimointi, joka antaa k‰ytt‰j‰n keskitty‰ semantiikkaan tehokkuuden sijaan.
Laajennettavuus.
K‰ytt‰j‰t voivat luoda omia funktioitaan erikoisk‰yttˆiseen prosessointiin. \cite{pig17}

Toteutus on muunnettu uudemmalle MovieLens datasetin versiolle, mutta muutoin koodi on uudelleen k‰ytetty alkuper‰isess‰ muodossaan. \cite{pig_original_code} \cite{pig_own_code}

\end{document}