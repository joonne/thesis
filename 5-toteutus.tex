\documentclass[main.tex]{thesis.tex}
\begin{document}
	
\lstset{
	columns=flexible,
	breaklines=true,
	tabsize=2,
	language=Scala,
	commentstyle=\color{scalacomment},
	keywordstyle=\color{blue},
	numbers=left,
	numbersep=15pt,
}

\chapter{Toteutus}

T‰ss‰ luvussa esitet‰‰n tyˆn toteutuksen oleelliset osat.
Opetusdata, sen lataaminen ja siistiminen Sparkia varten.
Projektin rakenne.
Mallin opettaminen.
Ennustusten ker‰‰minen mallin avulla.

\section{Opetusdata}

GroupLens Research on ker‰nnyt ja laittanut saataville aineistoja MovieLens-sivustolta.
Aineistot on ker‰tty useiden aikajaksojen aikana, riippuen aineiston koosta.
MovieLens 20M aineisto sis‰lt‰‰ 20 000 000 (kaksikymment‰ miljoonaa) arviota, jotka ovat antaneet 138 000 k‰ytt‰j‰‰ 27 000 elokuvalle.
MovieLens 20M aineisto koostuu $movies.csv$ and $ratings.csv$ tiedostoista. \cite{movieLens17}

\captionof{table}{N‰yte \textit{movies.csv} tiedostosta}
\begin{tabular}{lll}
	movieId & title & genres \\ \hline
	1 & Toy Story (1995) & Adventure|Animation|Children \\
	2 & Jumanji (1995) & Adventure|Children|Fantasy \\
	3 & Grumpier Old Men (1995) & Comedy|Romance \\
	4 & Waiting to Exhale (1995) & Comedy|Drama|Romance \\
	5 & Father of the Bride Part II (1995) & Comedy \\
	6 & Heat (1995) & Action|Crime|Thriller \\
	7 & Sabrina (1995) & Comedy|Romance \\
	8 & Tom and Huck (1995) & Adventure|Children \\
	9 & Sudden Death (1995) & Action \\
	10 & GoldenEye (1995) & Action|Adventure|Thriller \\
\end{tabular}

\newpage

\captionof{table}{N‰yte \textit{ratings.csv} tiedostosta}
\begin{tabular}{llll}
	userId & movieId & rating & timestamp \\ \hline
	1 & 31 & 2.5 & 1260759144 \\
	1 & 1029 & 3.0 & 1260759179 \\
	1 & 1061 & 3.0 & 1260759182 \\
	1 & 1129 & 2.0 & 1260759185 \\
	1 & 1172 & 4.0 & 1260759205 \\
	1 & 1263 & 2.0 & 1260759151 \\
	1 & 1287 & 2.0 & 1260759187 \\
	1 & 1293 & 2.0 & 1260759148 \\
	1 & 1339 & 3.5 & 1260759125 \\
\end{tabular}

~

Toteutuksessa k‰ytettiin RDD-pohjaista rajapintaa, sill‰ dataset-pohjainen rajapinta ei ole viel‰ t‰ysin toiminnallinen yhteisˆllisen suodatuksen ongelmille.
Aineiston lataaminen voidaan tehd‰ dataset-rajapintaa hyˆdynt‰en, mutta varsinainen suositus t‰ytyy tehd‰ RDD-rajapintaa k‰ytt‰en.
Dataset-rajapinta tarjoaa useita parannuksia, kuten esimerkiksi yksinkertaisemman tiedon lataamisen.

\section{Projektin rakenne}

Ensimm‰inen askel itsen‰isen Spark-sovelluksen rakentamisessa on tehd‰ oikeanlainen kansiorakenne ja luoda tiedosto, jossa kuvaillaan sovelluksen riippuvuudet.
Itsen‰isell‰ Spark-sovelluksella tarkoitetaan k‰yttˆvalmista $JAR$-tiedostoa (Java ARchive), joka voidaan jakaa Spark-klusterille ja se sis‰lt‰‰ sek‰ koodin ett‰ kaikki riippuvuudet.
T‰t‰ varten l‰hdekoodi tulee saada paketoitua ja t‰m‰ saavutetaan SBT-tyˆkalulla.
SBT (Scala Build Tool) on k‰‰nnˆstyˆkalu Scala, Java ja C++-kielille, jonka avulla l‰hdekoodi saadaan sek‰ k‰‰nnetty‰ ett‰ paketoitua JAR:iksi \cite{sbt}.

Sovelluksia voidaan ottaa k‰yttˆˆn klusterissa \textit{spark-submit} tyˆkalun avulla, joka mahdollistaa Sparkin kaikkien tuettujen klusterinhallintatyˆkalujen k‰ytt‰misen yhten‰isen k‰yttˆliittym‰n kautta.
T‰m‰ ominaisuus osoittautui eritt‰in hyˆdylliseksi kun sovellusta ajettiin EMR-klusterissa, sill‰ spark-submit tyˆkalu otti parametrinaan vain k‰‰nnetyn JAR:in ja alkoi ajamaan sovellusta.
T‰ss‰ tyˆss‰ "klusteri" tulee sis‰lt‰m‰‰n vain master-solmun sek‰ yhden worker-solmun, mutta periaatteessa kyseess‰ on kuitenkin klusteri, vain eritt‰in pieni sellainen.

\newpage

\begin{lstlisting}[caption=Sovelluksen paketointi ja ajaminen klusterissa,language=sh]
sbt package
spark-submit movielens-recommendations_2.11-1.0.jar
\end{lstlisting}

~

Alla olevassa esimerkiss‰ 5.3 ladataan tyˆss‰ k‰ytetyt suositukset RDD rajapintaa k‰ytt‰en.

\lstset {
	language=Scala,
	basicstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	showstringspaces=false,
	tabsize=2,
	breaklines=true,
	breakatwhitespace=false,
}

\begin{lstlisting}[caption=Suositusten lataaminen RDD rajapintaa k‰ytt‰en]
val ratings = sc.textFile("ml-latest-small/ratings.csv")
  .mapPartitionsWithIndex((i, it) => if (i == 0) it.drop(1) else it)
  .map { line =>
    val fields = line.split(",")
    val timestamp = fields(3).toLong % 10
    val userId = fields(0).toInt
    val movieId = fields(1).toInt
    val rating = fields(2).toDouble 

    (timestamp, Rating(userId, movieId, rating))
  }
\end{lstlisting}

~

Alla olevassa esimerkiss‰ 5.4 ladataan tyˆss‰ k‰ytetyt suositukset Dataset-rajapintaa k‰ytt‰en.

\lstset {
	language=Scala,
	basicstyle=\footnotesize,
	numbers=left,
	stepnumber=1,
	showstringspaces=false,
	tabsize=2,
	breaklines=true,
	breakatwhitespace=false,
}

\begin{lstlisting}[caption=Suositusten lataaminen Dataset rajapintaa k‰ytt‰en]
val ratings = spark.read.csv("ml-latest-small/ratings.csv")
	.mapPartitionsWithIndex((i, it) => if (i == 0) it.drop(1) else it)
	.map { fields =>
		val userId = fields(0).asInstanceOf[String].toInt
		val movieId = fields(1).asInstanceOf[String].toInt
		val rating = fields(2).asInstanceOf[String].toFloat
		val timestamp = fields(3).asInstanceOf[String].toDouble % 10

		Rating(userId, movieId, rating, timestamp)
  }
\end{lstlisting}

\newpage

\section{Opetusdatan lataaminen Spark sovellukseen}

Alla olevassa koodilistauksessa 5.5 on esimerkki opetusdatan lataamisesta S3:sta.

\begin{lstlisting}[caption=Aineiston lataaminen]
val ratings = sc.textFile("s3n://bucket/ratings.csv")
  .mapPartitionsWithIndex((i, it) => if (i == 0) it.drop(1) else it)
  .map { line =>
		val fields = line.split(",")
		val timestamp = fields(3).toLong
		val userId = fields(0).toInt
		val movieId = fields(1).toInt
		val rating = fields(2).toDouble

		(timestamp, Rating(userId, movieId, rating)
  }	
\end{lstlisting}

Riveill‰ 1-11 luodaan RDD $ratings$ lataamalla csv-tiedosto.
Tiedostosta suodatetaan ensin pois otsikkorivit ja t‰m‰n j‰lkeen tiedosto k‰yd‰‰n l‰pi rivi kerrallaan ja p‰tkit‰‰n pilkulla erotetut arvot taulukkoon k‰ytt‰en Scalan String-luokan sis‰‰nrakennettua $split$ funktiota.
T‰m‰n j‰lkeen taulukossa olevista arvoista muodostetaan pareja (tuple).
Huomionarvoista on se, kuinka tiedostoihin voidaan viitata suoraan S3:n tiedoston nimell‰ ja Spark osaa hakea tiedostot suoraan S3-bucketista.
Opetusdataa ei juuri tarvinnut siisti‰, sill‰ opetukseen k‰ytettiin valmista, hyvin j‰sennelty‰ datasetti‰.

\section{Mallin opettaminen}

Alla olevassa koodilistauksessa 5.6 on esitetty esimerkki mallin opettamisesta.

\begin{lstlisting}[caption=Mallin opettaminen]
for (rank <- ranks; lambda <- lambdas; numIter <- numIters) {
	val model = ALS.train(training, rank, numIter, lambda)
	val validationRmse =
		computeRmse(model, validation, numValidation)
	
	if (validationRmse < bestValidationRmse) {
		bestModel = Some(model)
		bestValidationRmse = validationRmse
		bestRank = rank
		bestLambda = lambda
		bestNumIter = numIter
	}
}

\end{lstlisting}

Yll‰ olevassa esimerkiss‰ suoritetaan varsinainen mallin opetus.
Opetus tapahtuu niin, ett‰ opetetaan muutama versio mallista ja valitaan malleista paras k‰ytt‰en RMSE-metriikkaa.
Koodin tasolla opetus tapahtuu k‰ytt‰en MLlib / ALS kirjaston funktiota $train$, joka ottaa sis‰‰ntulonaan $ratings$, $rank$, $iterations$ sek‰ $lambda$ parametrit:

\begin{itemize}
	\item $ratings$ on RDD Rating olioita, jotka sis‰lt‰v‰t k‰ytt‰j‰n tunnisteen, elokuvan tunnisteen ja suosituksen
	\item $rank$ on piilevien ominaisuuksien sis‰llytett‰v‰ m‰‰r‰
	\item $iterations$ on ALS algoritmin iteraatioiden m‰‰r‰
	\item $lambda$ on regularisaatio-parametri, jolla yritet‰‰n ehk‰ist‰ mallin ylioppimista
\end{itemize}

Tutkimuksessa \cite{miryala17} on tutkittu parhaita parametreja ALS-algoritmille ja p‰‰dytty lambda-arvoon 0.1 sek‰ iteraatioiden m‰‰r‰‰n 20.
Parhautta on tutkittu RMSE-metriikan kautta ja kyseisill‰ parametreilla RMSE saadaan pienimmilleen eli mallin voidaan sanoa sovittuvan parhaiten opetusdataan.
Tutkimuksessa oltiin p‰‰dytty arvoon 0.819942, kun taas paras itse opetettu malli p‰‰tyi RMSE arvoon 0.807167.
Omassa opetuksessa eroavaisuuksina olivat t‰m‰n hetken l‰hin vastaava datasetti, joka ei ollut aivan niin suuri kuin tutkimuksessa k‰ytetty, myˆs opetus datojen suhde oli hieman eri, sill‰ oman toteutuksen RMSE-validointi tarvitsi oman osansa datasta, olisi tietysti voitu k‰ytt‰‰ validointiin myˆs samaa dataa kuten ilmeisesti tutkimuksessa oli tehty tai sitten RMSE oli arvioitu eri tekniikkaa k‰ytt‰en.
Tutkimuksessa paras arvo saatiin 80-20 datasetti‰ k‰ytt‰en ja omassa opetuksessa k‰ytˆss‰ oli 60-20-20 datasetti.

% TODO: taulukko omien koulutusten tuloksista miten lambda omissa vaikutti?

\newpage

\section{Ennustaminen}

Alla olevassa koodilistauksessa 5.7 on esitetty esimerkki suositusten ennustamisesta.

\begin{lstlisting}[caption=Suositusten ennustaminen]
val myRatedMovieIds = personalRatings.map(_.product).toSet
val candidates = sc.parallelize(movies.keys.filter(!myRatedMovieIds.contains(_)).toSeq)

val recommendations = bestModel.get
	.predict(candidates.map((0, _)))
	.collect()
	.sortBy(- _.rating)
	.take(10)
\end{lstlisting}

~

Yll‰ olevassa koodilistauksessa haetaan henkilˆkohtaiset suositukset k‰ytt‰m‰ll‰ mallin $predict$-metodia, joka ottaa parametrinaan mahdollisten elokuvien joukon.
Mahdollisilla elokuvilla tarkoitetaan elokuvia, joita k‰ytt‰j‰ ei ole viel‰ n‰hnyt, eli ne eiv‰t sis‰lly $personalRatings$ muuttujan sis‰lt‰miin elokuviin.
$bestModel$ on aiemmin talteen otettu parhaan RMSE-arvon omaava malli. Tarkemmin sanottuna se on mallin sis‰lt‰m‰ $Option$ muuttuja, jonka sis‰ll‰ olevaan malliin p‰‰st‰‰n k‰siksi $get$-funktion avulla.

\newpage

\section{Apufunktiot}

Alla olevassa kooodilistauksessa 5.8 esitet‰‰n k‰ytetyt apufunktiot.

\begin{lstlisting}[caption=Apufunktiot]
def computeRmse(
	model: MatrixFactorizationModel,
	data: RDD[Rating],
	n: Long
): Double = {
	val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))
	val predictionsAndRatings = predictions
		.map(x => ((x.user, x.product), x.rating))
		.join(data.map(x => ((x.user, x.product), x.rating)))
		.values
	
	math.sqrt(
		predictionsAndRatings
			.map(x => (x._1 - x._2) * (x._1 - x._2))
			.reduce(_ + _) / n
	)
}
\end{lstlisting}

Yll‰ olevassa koodilistauksessa esitet‰‰n apufunktio $computeRMSE$, jonka avulla evaluoidaan opetetun mallin virhett‰.
Apufunktio on ehk‰ hieman v‰h‰inen nimitys, sill‰ kuten kappaleessa 2 todettiin, k‰ytet‰‰n RMSE:t‰ kriteerin‰ sille, ett‰ kuinka hyvin malli sovittuu opetusdataan.
Lis‰ksi vertailevassa tutkimuksessa RMSE-arvoa k‰ytettiin toteamaan paras malli vaihtoehdoista.

\end{document}