\documentclass[main.tex]{thesis.tex}
\begin{document}

\chapter{Yhteenveto}

Tässä kappaleessa esitetään yhteenveto.

\section{Johtopäätökset}

Suosittelujärjestelmän rakentamiseen on olemassa monia mahdollisia toteutusvaihtoehtoja.
Apache Spark vaikutti mielenkiintoiselta opiskelukohteelta ja tulevaisuuden kannalta hyödylliseltä.
Scala-ohjelmoinnin oppiminen vaikutti myöskin teknologian valintaan.
AWS-palveluiden tuntemus on varsin hyödyllinen taito ja tässä työssä tuli pieni palanen opittua sieltäkin maailmasta lisää.
Olemassaolevien suosittelujärjestelmien tai analytiikkajärjestelmien evaluointi tulisi suorittaa ennen suosittelujärjestelmän valintaa.
Suuremman datasetin käyttäminen sekä isomman arvostelumäärän tarjoaminen järjestelmälle voisi parantaa tuloksia.

AWS analyysi tähän?

- minkälaista laskutus / toiminta voisi mieluummin olla?
- miten tein
- miten olisi pitänyt tehdä

Pystytin AWS EMR liukuhihnan (pipeline) ohjeiden VIITE mukaisesti. Nimi on On-Demand, kuten VIITE sanotaan, mutta tosiasiassa varatut EC2 instanssit pysyvätkin ajossa kellon ympäri. Tätä ei varsinaisesti kommunikoitu missään vaiheessa, vaan asiaan havahtui vasta laskun saavuttua. Kuukauden mittaisesta EC2 (malli medium?) instanssien ajamisesta olisi tullut maksettavaa 1000 dollarin verran (verojen kanssa 1200 euroa?). Onneksi asian sai selvitettyä asiakaspalvelun kanssa ja AWS insinöörit tarkistivat pyynnöstäni lokeista että olin tosiasiassa käyttänyt EMR liukuhihnaani vain muutaman kerran kuten kerroinkin. AWS supportille kiitosta siitä kuinka mutkattomasti asia hoitui lopulta: pyyhkivät kuukauden laskun kokonaan ja lisäsivät kuluvalle kuulle krediittejä sen verran että lasku tulisi kuitattua.

Oikea keino olisi ollut ajaa tarvittavat eräajot ja tuloksien saannin jälkeen pysäyttää liukuhihna, jolloin varatut resurssit olisi vapautettu. Huonoa tässä on se että samaa liukuhihnaa ei ehkä saa uudestaan käyntiin?

Parempaa asiakaskokemusta olisi tiedottaa paremmin että tämä palvelu tosiaan varaa X määrän resursseja koko ajan, mutta se taitaa periaatteessa olla sertifikaattien tarkoitus osittain että oppii nämä nippelinappelit?
EMR pipeline olisi myös voinut mennnä "nukkumaan" kuten jotkut pilvipalvelut toimivat.
EMR pipeline olisi voinut terminoitua kokonaan X ajan käyttämättömyyden takia -> ehkä ei koska tulokset voisi kadota virtuaalikoneelta.

EMR pystytys

- lessons learnt
- mikä meni vikaan

EMR pystytys komentoriviltä

- workflow?

En saanut hyviä tuloksia

Saadut tulokset eivät ole palveluiden kuten Netflix tasolla, mutta ei sitä varmaan kannattanut odottaakaan. Yllättävää oli tosin se, kuinka huonoja saadut suositukset olivat. Yllättäviä kyllä, mutta mikään elokuvista ei kuulostanut soveliailta.

\section{Tulevaa työtä}

MLlib-kirjastoa voitaisiin tutkia uudestaan siinä vaiheessa, kun Dataset-rajapintaa voidaan käyttää MLlib:n kanssa.
Toteutusta yritettiin myös Dataset-rajapintaa hyväksikäyttäen, mutta kaikki ominaisuudet eivät olleet tuolloin vielä käytössä.

Yhteisöllistä suodatusta voidaan tietenkin käyttää muuhunkin tarkoitukseen kuin elokuvien suositteluun, kuten esimerkiksi kirjojen.
Olisikin mielenkiintoista tutkia myös jotain muuta ongelmaa ja soveltaa siihen ALS-algoritmia.

Verratun tutkimuksen \cite{miryala17} mukaista mallia voitaisiin vielä tutkia lisää, jos selviäisi keino, jolla RMSE:tä arvioitiin.
Pitäisi siis esimerkiksi selvittää, oliko kyseisen tutkimuksen 60-40 suhteessa jaetun aineiston testidatasta osa käytetty validointiin kuten omassa toteutuksessa tehtiin, jossa aineisto jaettiin 60-20-20 suhteessa.
Mikäli olisi runsaammin AWS resursseja käytössä, niin olisi myös melko suoraviivaista testailla montaa muutakin kombinaatiota mallin parametreille.

Työssä mainituista teknologioista esimerkiksi \textit{spark-submit} -työkalua voitaisiin tutkia lisää.
Olisi mielenkiintoista ymmärtää, kuinka klusterinhallinta toimii ja miten Spark tehtäviä (Spark Job) jaetaan eri noodeille.
Nykyisessä toteutuksessa voidaan olettaa, että \textit{spark-submit} etsii tarvittavat parametrit automaattisesti EMR-klusterista.
Kuten aliluvussa \ref{emr} mainittiin, EMR-klusteri on Hadoop-klusteri ja \textit{spark-submit} työkalun avainominaisuutena pidetään klusterinhallinnan helpottumista.
Sparkin hajautetun ohjelmointimallin kannalta olisi myös mielenkiintoista tutkia sulkeumia ja erityisesti sitä, kuinka ne toimivat oikeassa klusterissa.

\end{document}