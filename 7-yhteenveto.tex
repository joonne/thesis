\documentclass[main.tex]{thesis.tex}
\begin{document}

\chapter{Yhteenveto}

Tässä kappaleessa esitetään yhteenveto.

\section{Johtopäätökset}

Suosittelujärjestelmän rakentamiseen on olemassa monia mahdollisia toteutusvaihtoehtoja.
Apache Spark vaikutti mielenkiintoiselta opiskelukohteelta ja tulevaisuuden kannalta hyödylliseltä.
Scala-ohjelmoinnin oppiminen vaikutti myöskin teknologian valintaan.
AWS-palveluiden tuntemus on varsin hyödyllinen taito ja tässä työssä tuli pieni palanen opittua sieltäkin maailmasta lisää.
Olemassaolevien suosittelujärjestelmien tai analytiikkajärjestelmien evaluointi tulisi suorittaa ennen suosittelujärjestelmän valintaa.
Suuremman datasetin käyttäminen sekä isomman arvostelumäärän tarjoaminen järjestelmälle voisi parantaa tuloksia.

\section{Tulevaa työtä}

MLlib-kirjastoa voitaisiin tutkia uudestaan siinä vaiheessa, kun Dataset-rajapintaa voidaan käyttää MLlib:n kanssa.
Toteutusta yritettiin myös Dataset-rajapintaa hyväksikäyttäen, mutta kaikki ominaisuudet eivät olleet tuolloin vielä käytössä.

Yhteisöllistä suodatusta voidaan tietenkin käyttää muuhunkin tarkoitukseen kuin elokuvien suositteluun, kuten esimerkiksi kirjojen.
Olisikin mielenkiintoista tutkia myös jotain muuta ongelmaa ja soveltaa siihen ALS-algoritmia.

Verratun tutkimuksen \cite{miryala17} mukaista mallia voitaisiin vielä tutkia lisää, jos selviäisi keino, jolla RMSE:tä arvioitiin.
Pitäisi siis esimerkiksi selvittää, oliko kyseisen tutkimuksen 60-40 suhteessa jaetun aineiston testidatasta osa käytetty validointiin kuten omassa toteutuksessa tehtiin, jossa aineisto jaettiin 60-20-20 suhteessa.
Mikäli olisi runsaammin AWS resursseja käytössä, niin olisi myös melko suoraviivaista testailla montaa muutakin kombinaatiota mallin parametreille.

Työssä mainituista teknologioista esimerkiksi \textit{spark-submit} -työkalua voitaisiin tutkia lisää.
Olisi mielenkiintoista ymmärtää, kuinka klusterinhallinta toimii ja miten Spark tehtäviä (Spark Job) jaetaan eri noodeille.
Nykyisessä toteutuksessa voidaan olettaa, että \textit{spark-submit} etsii tarvittavat parametrit automaattisesti EMR-klusterista.
Kuten aliluvussa \ref{emr} mainittiin, EMR-klusteri on Hadoop-klusteri ja \textit{spark-submit} työkalun avainominaisuutena pidetään klusterinhallinnan helpottumista.
Sparkin hajautetun ohjelmointimallin kannalta olisi myös mielenkiintoista tutkia sulkeumia ja erityisesti sitä, kuinka ne toimivat oikeassa klusterissa.

\end{document}