\documentclass[main.tex]{thesis.tex}
\begin{document}

\chapter{Yhteenveto}

Tässä kappaleessa esitetään yhteenveto.

\section{Johtopäätökset}

Suosittelujärjestelmän rakentamiseen on olemassa monia mahdollisia toteutusvaihtoehtoja.
Apache Spark vaikutti mielenkiintoiselta opiskelukohteelta ja tulevaisuuden kannalta hyödylliseltä.
Scala-ohjelmoinnin oppiminen vaikutti myöskin teknologian valintaan.
AWS-palveluiden tuntemus on varsin hyödyllinen taito ja tässä työssä tuli pieni palanen opittua sieltäkin maailmasta lisää.
Suuremman aineiston käyttäminen sekä isomman arvostelumäärän tarjoaminen järjestelmälle voisi ajatella parantavan tuloksia.

Aluksi EMR-liukuhihnan pystyttämistä yritettiin vain Amazonin käyttöliittymän konsolin kautta, mutta ilman lisäohjeistusta kaikkien valintojen tutkiminen ja ymmärtäminen vaikutti turhan työläältä.
Etsinnän jälkeen sopivat ohjeistukset löytyivät ja EMR saatiin konfiguroitua.
Aiemman EMR opiskelun ansiosta videolla mainitut asiat olivat helposti omaksuttavissa, kuten esimerkiksi salaisuuksien (credentials) lisääminen ja EMR:n virtuaalikoneisiin yhdistäminen.
Lisäksi aiemmat tiedot Amazon S3:sta sekä yleiset komentorivitaidot olivat hyödyksi.
Jälkeen päin mietittynä sopivan ohjeistuksen etsimiseen käytetyn ajan olisi voinut tietysti myös käyttää EMR:n opiskeluun Amazonin omien ohjeistusten mukaan.

Jälkeen päin opiskeltuani lisää siitä, että miten olisin voinut välttää laskun, selvisi että on olemassa erilliset AWS:n palvelut laskujen monitorointiin ja tulevan laskun ennustamiseen.
Amazon Cost Explorer mahdollistaa laskujen tutkimisen, Amazon Budget puolestaan valvoo tulevan laskun määrää ja ilmoittaa mikäli ollaan menossa asetetuista rajoista yli.

Oletusarvoisesti EMR kirjottaa logit S3:een ja tämä saattaisi helposti johtaa Free Tier pyyntöjen rajan ylittämiseen.
AWS lähetti asiasta onneksi viestin ja näin ollen päästiin ratkomaan kyseistä konfiguraatiovirhettä.
EMR-klusteria ei ole mahdollista muokata jälkeenpäin, joten se täytyy poistaa (terminate), jotta lokien kirjoittaminen saattin poistettua käytöstä.
Amazon Free Tier sisältää S3:n osalta 2000 kutsua (luku/kirjoitus yhteensä) kuukaudessa ja koska kaikki Spark-sovelluksen tuottamat lokit kirjoitetaan, niin tämä raja tuli vastaan nopeasti.

Työssä käytetty EMR-liukuhihna pystytettiin ohjeiden \cite{levelup} mukaisesti.
Pystytettävän palvelun nimi on On-Demand Pipeline, mutta tosiasiassa varatut EC2-instanssit pysyvät ajossa kellon ympäri.
Tämän olisi voinut välttää laittamalla luvussa 5 mainittuun valintaruutuun valinnan, joka olisi sulkenut liukuhihnan ohjelman suorituksen jälkeen, mutta tässä työssä tavoitteena oli päästä ajelemaan silloin kun oli tehty uusi versio.
Tätä ei varsinaisesti kommunikoitu missään vaiheessa, vaan asiaan havahtui vasta laskun saavuttua.
Kuukauden mittaisesta EC2 (m3.xlarge) -instanssien ajamisesta olisi tullut maksettavaa reilu 1000 dollarin verran.

\begin{figure}[h]
	\caption{AWS lasku}
	\centering
	\includegraphics[scale=0.3]{aws_bill}
\end{figure}

Laskutus toimii niin, että virtuaalikoneiden ajamisesta täytyy maksaa 0.266 dollaria/h ja tämän lisäksi 0.07 dollaria/h EMR-lisämaksua.
Onneksi asian sai selvitettyä asiakaspalvelun kanssa ja AWS-asiakaspalvelun insinöörit tarkistivat pyynnöstäni lokeista että olin tosiasiassa käyttänyt EMR-liukuhihnaa vain muutaman kerran, kuten kerroinkin.
AWS:n asiakaspalvelu ansaitsee kiitosta siitä kuinka mutkattomasti asia hoitui lopulta: pyyhkivät kuukauden laskun kokonaan ja lisäsivät kuluvalle kuulle (heinäkuu 2018) krediittejä sen verran että lasku tulisi kuitattua.

Oikea keino olisi ollut pystyttää liukuhihna, ajaa tarvittavat eräajot ja tuloksien saannin jälkeen pysäyttää liukuhihna, jolloin varatut resurssit olisi vapautettu.
Huonoa tässä on se, että samaa liukuhihnaa ei ilmeisesti saa uudestaan käyntiin, jolloin ainakin virtuaalikoneella olevat asiat ovat lopullisesti menetettyjä kun se sulkeutuu.
Terminoitu, eli pysäytetty liukuhihna jää kummittelemaan palveluun joksikin aikaa.
Aiemmin konfiguroitu liukuhihna on kuitenkin mahdollista kopioida uuden liukuhihnan pohjaksi, joten kerran konfiguroidusta liukuhihnasta on tässä mielessä hyötyä seuraavallakin kerralla.

Parempaa asiakaskokemusta olisi tiedottaa paremmin että tämä palvelu tosiaan varaa X määrän resursseja koko ajan.
EMR-liukuhihna olisi myös voinut mennnä "nukkumaan" kuten jotkut muut pilvipalvelut toimivat.
EMR-liukuhihna olisi voinut terminoitua kokonaan X ajan käyttämättömyyden takia, tämä ei kuitenkaan olisi käytännöllistä, sillä tulokset katoaisivat virtuaalikoneelta.

Saadut tulokset eivät ole palveluiden, kuten Netflix tasolla, mutta ei sitä varmaan kannattanut odottaakaan.
Mielenkiintoista oli se, kuinka "huonoja" saadut suositukset olivat.
Yllättäviä ja uusia kylläkin, mutta mikään elokuvista ei kuulostanut soveliaalta tai mielekkäältä.
Tässä tosin voikin piillä juuri hyvän suosittelun raja, sillä luultavasti ihmisen muodostama mielipide vaikkapa pelkän nimen perusteella saattaa johtaa elokuvan hylkäämiseen.
Ihminen ei välttämättä ole täysin objektiivinen valitsemaan sitä, onko jokin suositeltu elokuva katsomisen arvoinen.
Elokuvan julkaisuvuosi, ohjaajan tunnettuus, näyttelijät ja jopa kansikuva herättävät mielipiteitä, jotka saattavat johtaa elokuvan hylkäämiseen tai ainakin siirtämiseen sille kuuluisalle "katson joskus" listalle.

\section{Tulevaa työtä}

MLlib-kirjastoa voitaisiin tutkia uudestaan, sillä Dataset-rajapintaa voidaan nyt käyttää yhteisösuodatuksen ongelmien ratkomiseen.
Toteutusta yritettiin alunperin myös Dataset-rajapintaa hyväksikäyttäen, mutta kaikki ominaisuudet eivät olleet tuolloin vielä käytössä.
Työtä aloittaessa Spark oli versiossa 1.5/1.6 ja työtä lopettaessa versiossa 2.3.
Ohjelmointimalli on vaihtunut RDD-perusteisesta rajapinnasta Dataset-perusteiseen rajapintaan.
MLlib-kirjasto on vaihtunut ML nimiseen kirjastoon.

Yhteisösuodatusta voidaan tietenkin käyttää muuhunkin tarkoitukseen kuin elokuvien suositteluun, kuten esimerkiksi kirjojen.
Olisikin mielenkiintoista tutkia myös jotain muuta ongelmaa ja soveltaa siihen ALS-algoritmia.

Verratun tutkimuksen \cite{miryala17} mukaista mallia olisi mahdollista tutkia lisää, jos selviäisi keino, jolla RMSE:tä arvioitiin.
Pitäisi siis esimerkiksi selvittää, oliko kyseisen tutkimuksen 60-40 suhteessa jaetun aineiston testidatasta osa käytetty validointiin kuten omassa toteutuksessa tehtiin, jossa aineisto jaettiin 60-20-20 suhteessa.
Mikäli AWS-resursseja olisi runsaammin käytössä, niin olisi myös melko suoraviivaista tutkia useampaakin kombinaatiota mallin parametreille.

Työssä mainituista teknologioista esimerkiksi \textit{spark-submit} -työkalua voitaisiin tutkia lisää.
Olisi mielenkiintoista ymmärtää, kuinka klusterinhallinta toimii ja miten Spark-tehtäviä (Spark Job) jaetaan eri solmuille.
Nykyisessä toteutuksessa on oletettu, että \textit{spark-submit} etsii tarvittavat parametrit automaattisesti EMR-klusterista, sillä niitä ei annettu eksplisiittisesti.
Etsintä voitaisiin toteuttaa esimerkiksi ympäristömuuttujien avulla.
Kuten aliluvussa \ref{emr} mainittiin, EMR-klusteri on Hadoop-klusteri ja \textit{spark-submit} työkalun avainominaisuutena pidetään klusterinhallinnan helpottumista.
Sparkin hajautetun ohjelmointimallin kannalta olisi myös mielenkiintoista tutkia sulkeumia (closure) ja erityisesti sitä, kuinka ne toimivat oikeassa klusterissa.

\end{document}