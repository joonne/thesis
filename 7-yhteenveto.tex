\documentclass[main.tex]{thesis.tex}
\begin{document}

\chapter{Yhteenveto}

Tässä kappaleessa esitetään yhteenveto.

\section{Johtopäätökset}

Suosittelujärjestelmän rakentamiseen on olemassa monia mahdollisia toteutusvaihtoehtoja.
Apache Spark vaikutti mielenkiintoiselta opiskelukohteelta ja tulevaisuuden kannalta hyödylliseltä.
Scala-ohjelmoinnin oppiminen vaikutti myöskin teknologian valintaan.
AWS-palveluiden tuntemus on varsin hyödyllinen taito ja tässä työssä tuli pieni palanen opittua sieltäkin maailmasta lisää.
Olemassaolevien suosittelujärjestelmien tai analytiikkajärjestelmien evaluointi tulisi suorittaa ennen suosittelujärjestelmän valintaa.
Suuremman datasetin käyttäminen sekä isomman arvostelumäärän tarjoaminen järjestelmälle voisi parantaa tuloksia.

Pystytin EMR-liukuhihnan (pipeline) ohjeiden VIITE mukaisesti.
Nimi on On-Demand, kuten VIITE sanotaan, mutta tosiasiassa varatut EC2-instanssit pysyvätkin ajossa kellon ympäri.
Tätä ei varsinaisesti kommunikoitu missään vaiheessa, vaan asiaan havahtui vasta laskun saavuttua.
Kuukauden mittaisesta EC2 (malli medium?) instanssien ajamisesta olisi tullut maksettavaa 1000 dollarin verran (verojen kanssa 1200 euroa?).
Onneksi asian sai selvitettyä asiakaspalvelun kanssa ja AWS asiakaspalvelun insinöörit tarkistivat pyynnöstäni lokeista että olin tosiasiassa käyttänyt EMR-liukuhihnaani vain muutaman kerran, kuten kerroinkin.
AWS:n asiakaspalvelulle kiitosta siitä kuinka mutkattomasti asia hoitui lopulta: pyyhkivät kuukauden laskun kokonaan ja lisäsivät kuluvalle kuulle krediittejä sen verran että lasku tulisi kuitattua.

Oikea keino olisi ollut pystyttää liukuhihna, ajaa tarvittavat eräajot ja tuloksien saannin jälkeen pysäyttää liukuhihna, jolloin varatut resurssit olisi vapautettu.
Huonoa tässä on se että samaa liukuhihnaa ei ehkä saa uudestaan käyntiin, jolloin ainakin virtuaalikoneella olevat asiat ovat lopullisesti menetettyjä kun se sulkeutuu.
Terminoitu, eli pysäytetty liukuhihna jää kummittelemaan palveluun joksikin aikaa, sen voi kyllä kopioida uudeksi liukuhihaksi, jolloin kerran konfiguroidusta liukuhihnasta on tässä mielessä hyötyä seuraavallakin kerralla.

Parempaa asiakaskokemusta olisi tiedottaa paremmin että tämä palvelu tosiaan varaa X määrän resursseja koko ajan.
EMR-liukuhihna olisi myös voinut mennnä "nukkumaan" kuten jotkut pilvipalvelut toimivat.
EMR-liukuhihna olisi voinut terminoitua kokonaan X ajan käyttämättömyyden takia -> ehkä ei koska tulokset voisi kadota virtuaalikoneelta.

EMR pystytys piti tehdä käytännössä kolmannen osapuolen videon perusteella, sillä AWS:n omat ohjeistukset eivät olleet riittävät, tai ainakin ne olivat vaikeaselkoiset. Osa sertifikaattien tarkoitusta? LINKKI

Saadut tulokset eivät ole palveluiden kuten Netflix tasolla, mutta ei sitä varmaan kannattanut odottaakaan.
Mielenkiintoista oli se, kuinka "huonoja" saadut suositukset olivat.
Yllättäviä ja uusia kylläkin, mutta mikään elokuvista ei kuulostanut soveliaalta tai mielekkäältä.
Tässä tosin voikin piillä juuri hyvän suosittelun raja, sillä luultavasti ihmisen muodostama mielipide pelkän nimen perusteella saattaa johtaa elokuvan hylkäämiseen.
Ihminen ei välttämättä ole täysin objektiivinen valitsemaan sitä, onko jokin suositeltu elokuva katsomisen arvoinen.
Elokuvan julkaisuvuosi, ohjaajan tunnettuus, näyttelijät ja jopa kansikuva herättävät mielipiteitä, jotka saattavat johtaa elokuvan hylkäämiseen tai ainakin siirtämiseen sille kuuluisalle "katson joskus" listalle.

\section{Tulevaa työtä}

MLlib-kirjastoa voitaisiin tutkia uudestaan siinä vaiheessa, kun Dataset-rajapintaa voidaan käyttää MLlib:n kanssa.
Toteutusta yritettiin myös Dataset-rajapintaa hyväksikäyttäen, mutta kaikki ominaisuudet eivät olleet tuolloin vielä käytössä.

Työtä aloittaessa MLlib-kirjasto

Yhteisöllistä suodatusta voidaan tietenkin käyttää muuhunkin tarkoitukseen kuin elokuvien suositteluun, kuten esimerkiksi kirjojen.
Olisikin mielenkiintoista tutkia myös jotain muuta ongelmaa ja soveltaa siihen ALS-algoritmia.

Verratun tutkimuksen \cite{miryala17} mukaista mallia voitaisiin vielä tutkia lisää, jos selviäisi keino, jolla RMSE:tä arvioitiin.
Pitäisi siis esimerkiksi selvittää, oliko kyseisen tutkimuksen 60-40 suhteessa jaetun aineiston testidatasta osa käytetty validointiin kuten omassa toteutuksessa tehtiin, jossa aineisto jaettiin 60-20-20 suhteessa.
Mikäli AWS-resursseja olisi runsaammin käytössä, niin olisi myös melko suoraviivaista testailla montaa muutakin kombinaatiota mallin parametreille.

Työssä mainituista teknologioista esimerkiksi \textit{spark-submit} -työkalua voitaisiin tutkia lisää.
Olisi mielenkiintoista ymmärtää, kuinka klusterinhallinta toimii ja miten Spark-tehtäviä (Spark Job) jaetaan eri solmuille.
Nykyisessä toteutuksessa voidaan olettaa, että \textit{spark-submit} etsii tarvittavat parametrit automaattisesti EMR-klusterista.
Kuten aliluvussa \ref{emr} mainittiin, EMR-klusteri on Hadoop-klusteri ja \textit{spark-submit} työkalun avainominaisuutena pidetään klusterinhallinnan helpottumista.
Sparkin hajautetun ohjelmointimallin kannalta olisi myös mielenkiintoista tutkia sulkeumia ja erityisesti sitä, kuinka ne toimivat oikeassa klusterissa.

\end{document}